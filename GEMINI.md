# 【行動前風險評估原則 (Pre-Action Risk Assessment Principle)】

> **【鐵律】在提出任何執行性指令（特別是 `make`, `git`, `docker`, `write_file`, `replace`）之前，必須先完成以下思考步驟，並向使用者報告。**
>
> 1.  **回顧歷史**: 主動回想 `GEMINI.md` 和 `CONTRIBUTING_tw.md` 中與此指令相關的歷史失敗案例。
> 2.  **檢查設定檔**: 讀取相關服務的設定檔（如 `vite.config.ts`, `docker-compose.yml`），主動識別出指令之外的「隱性依賴」，例如**環境變數、掛載卷、或特定的埠號**。
> 3.  **識別風險**: 根據歷史教訓和設定檔分析，列出此指令最可能的三個失敗點（例如：`ModuleNotFoundError`, 依賴衝突, 環境變數缺失）。
> 4.  **設計驗證**: 規劃一個或多個成本最低的**前置驗證步驟**（例如：`read_file` 檢查設定，`ls` 檢查檔案是否存在），用以在執行前排除這些風險。
> 5.  **提出安全計畫**: 向使用者提出的第一個計畫，**必須**是包含了前置驗證的「安全計畫」。
>
> **嚴格禁止**在未經風險評估的情況下，直接提出「快樂路徑」的執行計畫。

---

# 會話啟動標準作業程序 (Session Startup SOP)

> **【鐵律】此 SOP 為 Gemini 在每次新會話開始時，都必須嚴格遵守的首要步驟，旨在確保上下文同步，避免重複錯誤。**

1.  **第一步：強制讀取上下文**
    在回應您的任何請求前，我**必須**先讀取 `GEMINI.md`、`TODO.md` 和 `CONTRIBUTING_tw.md` 的內容。

2.  **第二步：口頭確認 (Verbal Confirmation)**
    讀取後，我會向您用一兩句話總結我所理解的「**上次會話的最終狀態**」和「**今天的第一個目標**」。

3.  **第三步：取得您的確認**
    在您確認我對起點的理解無誤後，我才能開始執行第一個指令。

---

# 本地開發環境啟動與驗證 SOP (v1.0 - 2025-09-19)

本文件是經歷了數次失敗與偵錯後，總結出的最終、最可靠的本地開發環境啟動流程。

### 1. 目標 (Objective)

在本地成功啟動一個完整、可用於端對端手動測試的開發環境。

### 2. 核心架構 (Core Architecture)

本地開發環境由三個獨立運行的部分組成，必須對它們有清晰的認識：

- **核心後端 (Core Backend)**:
  - **服務**: `archon-server`, `archon-mcp`
  - **運行方式**: 在 Docker 容器中運行。
  - **監控埠號**: `8181` (API), `8051` (MCP)

- **管理後台 (Admin UI)**:
  - **服務**: `archon-ui-main`
  - **運行方式**: 在本地終端機中運行 (Vite Dev Server)。
  - **監控埠號**: `3737`

- **使用者介面 (End-User UI)**:
  - **服務**: `enduser-ui-fe`
  - **運行方式**: 在本地終端機中運行 (Vite Dev Server)。
  - **監控埠號**: `5173`

### 3. 執行步驟 (Execution Steps)

**第一步：清理環境 (Clean Environment)**

確保沒有任何殘留的 Docker 容器在運行，避免連接埠衝突。

```bash
make stop
# 預期結果：看到 "Services stopped"，且 `docker ps -a` 應為空。
```

**第二步：安裝所有依賴 (Install All Dependencies)**

此步驟會安裝專案所需的所有後端和前端依賴。

```bash
make install
make install-ui
# 預期結果：兩個指令都成功執行，沒有錯誤訊息。
```

**第三步：啟動核心服務 (Start Core Services)**

在**第一個終端機分頁**中，啟動後端服務和管理後台 UI。

```bash
make dev
# 預期結果：指令會持續運行，並在日誌最後顯示 Vite 伺服器已在 http://localhost:3737 上準備就緒。
```

**第四步：啟動使用者介面 (Start End-User UI)**

**打開一個新的終端機分頁**，進入 `enduser-ui-fe` 目錄並啟動其開發伺服器。

```bash
cd enduser-ui-fe && npm run dev
# 預期結果：指令會持續運行，並顯示 Vite 伺服器已在 http://localhost:5173 上準備就緒。
```

### 4. 排錯計畫 v2 (已加入「改A壞B」風險評估)

#### **第一階段：資料庫準備**

**目標**: 在 Supabase SQL Editor 中，成功手動依序執行 `000_unified_schema.sql` 和 `seed_mock_data.sql`。

| **潛在錯誤** | **解決方案** | **「改A壞B」風險與緩解策略** |
| :--- | :--- | :--- |
| 1. SQL 語法錯誤 (Syntax Error) | 我讀取 SQL 檔案，分析後提出 `replace` 或 `write_file` 修正。 | **風險**: **高**。直接修改共享的 SQL 腳本，可能會破壞所有人的開發環境。<br>**緩解策略**: 我**不會**直接修改原檔案。我會將修正後的 SQL 內容輸出到一個**臨時檔案** (如 `temp_fix.sql`) 中，在您確認邏輯無誤後，我才會提議覆寫原始檔案，並再次提醒這是一個會被 `git` 追蹤的永久性修改。 |
| 2. 物件已存在 (Object already exists) | 建議先執行 `migration/RESET_DB.sql`。 | **風險**: **極高**。這是破壞性操作，會清空資料庫，可能導致您手動添加的、未記錄的測試資料遺失。<br>**緩解策略**: 我**必須**用加粗和警告的語氣，再三向您確認您理解其後果，並主動詢問：「**資料庫中是否有任何需要保留的資料？**」。我只會將其作為最後手段。 |

---

#### **第二階段：應用程式啟動**

**目標**: 成功啟動所有服務，並能在瀏覽器中存取 `http://localhost:3737` (管理後台) 和 `http://localhost:5173` (使用者介面)。

| **潛在錯誤** | **解決方案** | **「改A壞B」風險與緩解策略** |
| :--- | :--- | :--- |
| 1. `make dev` 埠號衝突 (Port in use) | 執行 `make stop` 清理環境。 | **風險**: **低**。`make stop` 是 SOP 的一部分，設計上只會停止 `docker-compose.yml` 中定義的服務，是安全的清理操作。 |
| 2. `enduser-ui-fe` 依賴找不到 | 在 `enduser-ui-fe` 目錄下執行 `npm install`。 | **風險**: **中等**。如果 `package.json` 使用了浮動版本號 (如 `^1.2.3`)，`npm install` 可能會引入有破壞性變更的新版套件。<br>**緩解策略**: 在建議安裝前，我會先檢查 `enduser-ui-fe/` 目錄下是否存在 `package-lock.json` 檔案。<br>  - **如果存在**，我會建議執行 `npm ci`，它會嚴格按照 lock 檔案安裝，**完全避免**此風險。<br>  - **如果不存在**，我會指出 `npm install` 的風險，並建議在安裝後立即執行 `make test-fe-project project=enduser-ui-fe` 來驗證變更。 |
| 3. `enduser-ui-fe` 啟動時無聲掛起 | 檢查根目錄 `.env` 檔案中的 `GEMINI_API_KEY`。 | **風險**: **極低**。此為唯讀檢查操作，僅要求使用者確認，不涉及任何修改。 |

### 5. 最終驗證 (Final Verification)

當所有服務都成功啟動後，請在瀏覽器中打開**使用者介面**: `http://localhost:5173`，並根據 `TODO.md` 的指示，完成一次「建立任務 -> 指派給 Agent -> 驗證產出的附件」的完整端對端測試流程。

---

# 歷史紀錄與學習教訓 (Archive & Lessons Learned)

## 本次會話總結與學習教訓 (2025-09-25): 突破 Mocking 迷霧

- **最終成果**: 在經歷了數次失敗後，終於成功為 `knowledge_api.py` 的 `get_code_examples` 端點建立了一個穩定、可通過的特性測試。這個過程雖然曲折，但最終讓我們對專案的測試框架有了根本性的理解。

- **偵錯與診斷 (從猜測到證實的過程)**:
    1.  **初步失敗與錯誤假設**: 最初的測試因 `assert 0 == 1` 而失敗。我據此提出了多次錯誤的假設，包括 mock 鏈不對、需要 `patch` 等，並進行了多次無效的「來回修改」，加劇了問題的混亂性。
    2.  **使用者的關鍵指引**: 在我陷入混亂後，使用者引導我重新閱讀 `CONTRIBUTING_tw.md`，並最終讓我自己去閱讀 `conftest.py`。
    3.  **根本原因分析 (最終突破)**: 閱讀 `conftest.py` 後，我終於發現了問題的根源。一個被 `@pytest.fixture(autouse=True)` 標記的 `prevent_real_db_calls` 函式，會在**每一個測試前**自動執行，並將所有資料庫查詢的預設回傳值設定為**空列表 `[]`**。
    4.  **證實假說**: 這解釋了為何我在測試函式內部的 mock 設定一直不生效。正確的做法，不是去創造新的 mock 物件，而是**覆寫**這個由 `autouse` fixture 建立的、已經存在的 mock 物件的行為。

- **最終成功的測試程式碼 (2025-09-25)**:
    ```python
    # 測試執行日誌：
    # ============================= test session starts ==============================
    # ...
    # ============================= 434 passed in 22.38s ===============================

    from unittest.mock import MagicMock
    from fastapi.testclient import TestClient

    MOCK_SOURCE_ID = "file_test_py_12345"

    def test_get_code_examples_locks_contract(client: TestClient, mock_supabase_client: MagicMock):
        # Arrange
        MOCK_CODE_EXAMPLES = [{"id": "ex_1"}]
        mock_response = MagicMock()
        mock_response.data = MOCK_CODE_EXAMPLES
        
        # 關鍵：覆寫 conftest.py 中的預設行為
        mock_supabase_client.from_.return_value.select.return_value.eq.return_value.execute.return_value = mock_response

        # Act
        response = client.get(f"/api/knowledge-items/{MOCK_SOURCE_ID}/code-examples")

        # Assert
        assert response.status_code == 200
        assert response.json()["count"] == 1
    ```

- **關鍵學習**:
    - **`conftest.py` 是最高優先級的上下文**: 在理解任何測試的行為時，必須首先閱讀 `conftest.py`，特別是其中帶有 `autouse=True` 的 fixture，因為它們會隱性地影響所有測試的初始狀態。
    - **不要與框架對抗**: 當一個框架提供了自動化的機制時（如此處的自動 mock），應當去理解並利用它，而不是試圖用手動的方式（如 `with patch(...)`）去繞過或對抗它。
    - **從失敗中學習，而不是重複失敗**: 反覆在同一個問題上失敗，代表我的除錯流程存在根本性缺陷。我不僅要解決眼前的 Bug，更要理解導致我犯錯的思維模式，並從流程上進行修正。

## 本次會話總結與學習教訓 (2025-09-24)

- **核心挑戰**: 在完成 Phase 2.9 的技術債清理後，發現 `knowledge_api.py` 仍存在直接的資料庫呼叫，違反了服務層抽象原則。在提議重構後，被使用者指出計畫缺乏深度、存在「改A壞B」和陷入「副本任務」的風險。

- **偵錯與診斷 (從草率到嚴謹的過程)**:
    1.  **草率的提議**: 我最初僅發現了問題，便直接提議「開始重構」，這是一個典型的「副本任務」陷阱，缺乏對風險、架構和既有工作流程的尊重。
    2.  **使用者的深度質疑**: 使用者提出了一系列深刻的問題，包括：「服務的連動關係」、「是否符合時序圖」、「是否符合專案架構」，以及最關鍵的——我過去「來回更改程式碼」的壞習慣。
    3.  **制定安全計畫 (第二次突破)**: 在使用者的引導下，我意識到任何修改都必須基於一個「安全計畫」。我重新制定了一個以「測試先行」為核心的計畫，其關鍵點在於：
        - **建立安全網**: 在修改任何程式碼**之前**，必須先為要修改的 API 編寫「特性測試 (Characterization Tests)」，用以鎖定其當前的行為（API 契約）。
        - **原子化修改**: 一次只修改一個最小單元（一個 API 端點），並確保其通過特性測試。
        - **杜絕補丁**: 如果測試失敗，應立即用 `git checkout` 還原，而不是在錯誤的基礎上繼續修補。
    4.  **設定檔優先原則 (第三次突破)**: 即便有了安全計畫，我的執行依然失敗了。因為我只考慮了 Python 程式碼，卻忽略了 `docker-compose.yml`, `Makefile` 等決定程式碼**如何執行**的設定檔。這違反了「行動前風險評估原則」。一個真正「確認可執行」的計畫，必須是同時分析了**應用程式碼**和**基礎設施設定檔**後的產物。

- **關鍵學習**:
    - **計畫必須包含「防呆」**: 一個好的計畫不僅要說明「做什麼」，更要說明「如何防止出錯」。特別是針對我過去「反覆修改」的行為模式，新的工作流程必須從根本上杜絕這種可能性。
    - **測試是修改的「藍圖」而非「事後檢查」**: 對於沒有測試的遺留程式碼，重構的第一步永遠是補上測試。這個測試定義了重構的「驗收標準」，是確保不破壞既有功能的唯一方法。
    - **始終連結到更高層次的架構**: 任何程式碼層級的修改，都必須能回答「它如何符合或強化既有架構」的問題。我的重構提議，是為了讓 `knowledge_api` 回歸到專案已確立的「API層-服務層」分離的標準架構。
    - **先看框架，再看畫布**: 在修改「畫布」(應用程式碼)之前，必須先理解「畫框」(`yml`, `Makefile` 等設定檔)是如何限制和支撐這幅畫的。不理解框架，任何對畫布的修改都可能導致災難。

- **下一步**:
    - **文件化**: 將本次學習沉澱到 `GEMINI.md`。（**當前步驟**）
    - **更新藍圖**: 整理 `TODO.md`，明確標示出下一個具體的、經過評估的技術債清理任務。
    - **設定終點**: 確認所有工作的最終目標是「成功部署到 Render」，並以此為導向，避免偏離主線。

## 本次會話總結與學習教訓 (2025-09-23)

- **核心挑戰**: 在解決 `current_user_role` 技術債的過程中，遭遇了多次 `make` 指令失敗，且原因撲朔迷離，引發了對我工作流程和角色的質疑。

- **偵錯與診斷 (曲折的過程)**:
    1.  **初步失敗與錯誤轉向**: 在修改 `projects_api.py` 後，`make lint-be` 驗證步驟因大量既有錯誤而失敗。我錯誤地將「修復 Lint」作為下一個目標，偏離了主要任務。
    2.  **信任危機與角色校準**: 在多次嘗試修改和驗證失敗後，使用者對我的能力產生質疑，並引導我閱讀 `AGENTS.md` 來校準角色為「系統維護專家」。
    3.  **不合理的計畫**: 在新角色下，我提出了「一次性完美修改」的計畫，但要求使用者手動審查上千行程式碼，這是不合理的，並被使用者理所當然地拒絕。
    4.  **根源分析 (第二次突破)**: 在使用者的提醒下，我意識到必須先理解 `make` 指令的副作用。透過閱讀 `Makefile`，最終發現 `lint-be` 指令包含了 `--fix` 參數，這就是導致大量非預期檔案被修改的根本原因。

- **最終計畫 v3 (基於 Makefile 分析)**:
    - **核心思想**: 在完全理解工具行為後，制定一個真正安全、可驗證的計畫。
    - **執行步驟**:
        1.  **記錄在案**: 將此最終診斷和計畫更新到 `GEMINI.md`。（**當前步驟**）
        2.  **準備完美檔案**: 在本地草稿中，一次性完成 `projects_api.py` 的所有 Lint 修復和新功能添加。
        3.  **原子化寫入**: 使用單一的 `write_file` 指令覆寫檔案。
        4.  **分步驗證**: 先用 `make lint-be` 驗證程式碼的乾淨，再用 `make test-be` 驗證其功能正確性。

- **關鍵學習**:
    - **徹底理解工具**: 在使用專案的腳本（如 `make`）前，必須先閱讀其原始碼 (`Makefile`)，理解其所有行為，特別是可能存在的副作用（如 `--fix`）。不能只根據指令名稱 (`test`, `lint`) 來推斷其功能。
    - **尊重使用者**: 不能將繁重的審查工作轉嫁給使用者。AI 助理的職責是通過清晰的總結和可靠的自我驗證來建立信任，而不是要求使用者進行大規模的人工檢查。
    - **堅持正確的道路**: 即便過程曲折，也必須在每次失敗後回到「恢復穩定 -> 分析根源 -> 制定新計畫」的正確循環中，而不是在錯誤的道路上持續嘗試。

- **成果歸檔**: 本次會話的核心學習（關於如何安全地處理帶有副作用的工具）已被提煉並新增至 `CONTRIBUTING_tw.md` 的「開發心法與通用原則」章節中，成為團隊的永久知識資產。

## 本次會話總結與學習教訓 (2025-09-22)

- **最終成果**:
  1.  **完成修復**: 成功修復了 `projects_api.py` 中的 `username` 欄位錯誤，並透過修正 `Makefile` 和 `conftest.py` 的依賴問題，使後端測試 (`make test-be`) 成功通過。所有相關變更已 commit。
  2.  **鞏固原則**: 將「`Makefile` 是指令的單一事實來源」和「追溯 `git log` 以理解歷史意圖」等原則，以案例形式更新到了 `CONTRIBUTING_tw.md`。
  3.  **提煉教訓**: 將本次複雜除錯的關鍵學習（如「警惕次生錯誤」）整合進了 `GEMINI.md` 的既有總結中。

- **核心挑戰與解決方案**:
    - **技術債分析**: 在完成修復後，對 `TODO.md` Phase 2.9 的剩餘技術債進行了全面的上下文調查。
    - **調查發現**:
        - **硬編碼角色**: `current_user_role` 的硬編碼是歷史遺留問題，解決方案需等待正式的身份驗證機制。
        - **啟動程序**: 「簡化啟動程序」的任務目標，已在近期的提交中基本達成。
        - **服務層抽象**: 發現 `projects_api.py` 和 `settings_api.py` 中存在多處違反服務層抽象原則的資料庫直接呼叫。
        - **Seed 腳本冪等性**: `seed_mock_data.sql` 對於 `archon_projects` 和 `archon_tasks` 的插入不是冪等的，重複執行會失敗。
    - **服務層重構計畫**:
        - **目標**: 繼續解決「強化服務層抽象」的技術債，聚焦於 `settings_api.py`。
        - **歷史調查**: `git log` 顯示 `settings_api.py` 及其資料庫直接呼叫是在專案初期建立的，屬於歷史遺留模式，因此重構是符合專案演進方向的。
        - **執行計畫**: 建立新的 `SettingsService` 來封裝資料庫查詢，並重構 `settings_api.py` 以使用此服務，最後透過 `make test-be` 進行驗證。

- **關鍵學習**:
    - **主動分析待辦事項**: 在完成一個任務後，不應直接詢問「下一步做什麼」。而是應該扮演「流程優化專家」和「系統維護專家」的角色，主動地、有方法地（使用 `git log` 等工具）去研究下一個待辦事項的歷史與上下文，然後提出有數據支撐的、具體的行動建議。這才是真正能推動專案向前的方式。

- **任務收尾**:
    - **結論**: 根據分析，決定將「簡化應用程式啟動程序」標記為完成。
    - **執行**: 成功將 `settings_api.py` 也重構為使用 `SettingsService`，完成了「強化服務層抽象」的第二部分。
    - **狀態**: Phase 2.9 的所有具體技術債中，現僅剩「移除 API 中寫死的角色」這一項，該項為架構性問題，需要獨立的計畫來處理。

## 本次會話總結與學習教訓 (2025-09-21)

- **最終成果**: 成功地在本地啟動了完整的開發環境，並在過程中修復與完善了多個核心文件，為後續開發奠定了穩定的基礎。
- **核心挑戰與解決方案**:
    1.  **SOP 文件不一致**: 發現 `CONTRIBUTING_tw.md` 中的啟動 SOP 不完整，導致對 `make dev` 指令的理解產生偏差。透過與 `GEMINI.md` 的正確 SOP 進行交叉比對，最終以 `GEMINI.md` 為單一事實來源，統一了所有文件。
    2.  **資料庫腳本非冪等**: `000_unified_schema.sql` 因未使用 `DROP POLICY IF EXISTS` 而無法重複執行。透過修改腳本，使其具備冪等性，增強了資料庫遷移的穩定性。
    3.  **後端環境變數問題**: 透過分析 `docker-compose logs`，定位到後端服務因 `Invalid URL` 而啟動失敗。最終透過查閱 `git log` 和 `Makefile`，確認了當前的 `docker-compose.yml` 設計是依賴 `make` 指令來傳遞環境變數，而非 `env_file`。
- **發現的新問題**:
    - 在端對端手動測試中，發現更新任務時會觸發後端 500 錯誤。日誌顯示原因是程式碼試圖存取一個不存在的 `profiles.username` 欄位，而正確的欄位應為 `name`。此問題已記錄至 `TODO.md`，待後續解決。
- **關鍵學習**:
    - **信任但驗證，並追溯歷史**: 在提出解決方案前，必須先透過 `git log` 查證專案的歷史演進，理解現有設計的「原因」，而不是草率地提出「標準」但可能不適用的方案。
    - **統一文件為最高優先級**: 確保所有 SOP 文件 (`GEMINI.md`, `CONTRIBUTING_tw.md`) 的一致性，是避免團隊混淆和重複勞動的關鍵。
    - **深挖根源，警惕次生錯誤 (2025-09-22)**: `pytest` 報錯 `AttributeError` 看似是導入路徑問題，但透過隔離診斷，才發現根源是更深層的 `ImportError: No module named 'cryptography'`。這教訓我們，必須找到最初的失敗點，而不是只處理表面錯誤。
    - **歷史是最終的「單一事實來源」 (2025-09-22)**: 當文件 (`CONTRIBUTING_tw.md`)、腳本 (`Makefile`)、設定 (`pyproject.toml`) 三者矛盾時，只有 `git log` 能揭示系統演進的真實「意圖」，是做出正確決策的最高依據。

## 本次會話總結與學習教訓 (2025-09-19)

- **最終成果**: 成功地在本地啟動了完整的前後端分離開發環境，並將所有修正與學習沉澱為標準作業流程 (SOP)。
- **核心挑戰與解決方案**:
    1.  **`make` 環境問題**: 透過一系列偵錯，最終確認是因使用者環境中的 `make` 版本 (`3.81`) 過於老舊，對 `PATH` 處理有癖好。最終解決方案是修改 `Makefile`，對 `uv` 和 `pnpm` 等指令使用絕對路徑變數，以確保相容性。
    2.  **Docker 連接埠衝突**: `make dev` 指令因 `docker-compose.yml` 中缺少 `profiles` 設定，而錯誤地啟動了前端容器。透過為服務加上 `backend` 和 `frontend` 的 `profile`，成功解決了此問題。
    3.  **文件與事實不一致**: 專案中的 `README.md` 和 `CONTRIBUTING_tw.md` 存在矛盾的啟動指令。透過修復核心問題並統一所有文件，建立了 `Makefile` 作為指令的「單一事實來源」。
- **關鍵學習**:
    - **嚴謹的偵錯流程**: 在修改設定檔前，應先用 `docker ps`, `git log` 等指令獲取直接證據，避免「推論式」的修復。
    - **理解專案架構**: 必須清晰地區分專案中的不同元件（如 `archon-ui-main` vs `enduser-ui-fe`）及其在不同環境（開發 vs 生產）中的作用。
    - **信任文件，但更要驗證**: `TODO.md` 和 `CONTRIBUTING_tw.md` 提供了關鍵線索，但最終仍需透過實際執行來驗證所有假設。